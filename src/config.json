{
    "encoder_depth": 12,
    "decoder_depth": 12,
    "act_layer": "SiLU",
    "gated_mlp": true,
    "patch_size": 16,
    "image_size": 224,
    "domains_in": [
      "tok_rgb@224",
      "tok_depth@224",
      "tok_semseg_n5k@224",
      "caption"
    ],
    "domains_out": [
      "tok_depth@224",
      "tok_semseg_n5k@224",
      "caption"
    ],
    "norm_bias": false,
    "mlp_bias": false,
    "proj_bias": false,
    "qkv_bias": false,
    "mlp_ratio": 4,
    "num_heads": 12,
    "dim": 768
  } 